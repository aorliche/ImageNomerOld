{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2793e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T2D', 'NGT', 'T2D_001', 'NGT_003', 'T2D_002', 'NGT_010', 'T2D_006', 'T2D_007', 'NGT_016', 'T2D_009', 'NGT_018', 'T2D_011', 'NGT_020', 'T2D_012', 'NGT_021', 'T2D_017', 'NGT_022', 'T2D_019', 'NGT_023', 'T2D_024', 'NGT_027', 'T2D_026', 'NGT_028', 'T2D_030', 'NGT_033', 'T2D_031', 'NGT_050', 'T2D_035', 'NGT_052', 'T2D_101', 'NGT_123', 'T2D_104', 'NGT_124', 'T2D_107', 'T2D_108', 'NGT_127', 'T2D_109', 'T2D_112', 'NGT_129', 'T2D_119']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "dictName = f'../../data/T2Dcounts.pkl'\n",
    "dataMap = None\n",
    "\n",
    "with open(dictName, 'rb') as f:\n",
    "    dataMap = pickle.load(f)\n",
    "    \n",
    "print(list(dataMap.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f3ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T2D_107', 'T2D_026', 'T2D_030', 'T2D_011', 'T2D_109', 'T2D_101', 'T2D_119', 'T2D_031', 'T2D_002', 'T2D_108', 'T2D_019', 'T2D_001', 'T2D_104', 'T2D_007', 'T2D_112', 'T2D_024', 'T2D_009', 'T2D_035', 'T2D_017', 'T2D_012', 'T2D_006'}\n",
      "{'NGT_124', 'NGT_010', 'NGT_003', 'NGT_023', 'NGT_050', 'NGT_123', 'NGT_028', 'NGT_052', 'NGT_020', 'NGT_033', 'NGT_022', 'NGT_127', 'NGT_016', 'NGT_021', 'NGT_027', 'NGT_018', 'NGT_129'}\n",
      "['basal', 'post', 'rec']\n"
     ]
    }
   ],
   "source": [
    "print(dataMap['T2D'])\n",
    "print(dataMap['NGT'])\n",
    "print(list(dataMap['T2D_001'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa78029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66023,)\n"
     ]
    }
   ],
   "source": [
    "print(dataMap['T2D_001']['basal'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e37ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66023, 111)\n",
      "['RP11-399E6.2', 'AC093151.1', 'FO681542.1', 'RP11-399E6.4', 'DPPA2P2', 'RPS6KA1', 'MIR1976', 'RN7SL679P', 'Y_RNA', 'RNU7-29P']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "countName = '../../data/GSE202295_gene_counts.txt'\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "pat = re.compile('\".*\" \"(.*)\" \"(.*)\" (.*)')\n",
    "\n",
    "def parseCountsLine(line, pat):\n",
    "    res = pat.search(line)\n",
    "    try:\n",
    "        groups = res.groups()\n",
    "        counts = [int(c) for c in groups[2].split(' ')]\n",
    "        return (groups[0], groups[1], counts)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def parseCountsFirstLine(line):\n",
    "    parts = line.split(' ')\n",
    "    pat = re.compile('\"([^A]+).*\"')\n",
    "    countsMap = {}\n",
    "    for i in range(2,len(parts)):\n",
    "        sampleId = pat.search(parts[i]).groups()[0]\n",
    "        countsMap[sampleId] = i-2\n",
    "    return countsMap\n",
    "    \n",
    "countsAll = []\n",
    "countNames1 = []\n",
    "countNames2 = []\n",
    "countsMap = None\n",
    "\n",
    "with open(countName, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        res = parseCountsLine(line, pat)\n",
    "        if res is None:\n",
    "            countsMap = parseCountsFirstLine(line)\n",
    "            continue\n",
    "        n1,n2,counts = res\n",
    "        countNames1.append(n1)\n",
    "        countNames2.append(n2)\n",
    "        countsAll.append(np.array(counts))\n",
    "        \n",
    "countsAll = np.stack(countsAll)\n",
    "print(countsAll.shape)\n",
    "print(countNames2[0:10])\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "452c0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43567 26941 52161 59236 23705  3014 12102  8093 33518 18699 60217 29246\n",
      " 26520 11845 47688  8623 35479 25801  2369 18803]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "imp = []\n",
    "with open('../../data/omics-regions/post_Corr.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        imp = [int(num) for num in re.split('\\s+', line) if len(num) > 0]\n",
    "        \n",
    "imp = np.array(imp)\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e415f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-1', '0-2', '0-3', '0-4', '0-5', '0-6', '0-7', '0-8', '0-9', '0-10']\n",
      "['259-260', '259-261', '259-262', '259-263', '260-261', '260-262', '260-263', '261-262', '261-263', '262-263']\n",
      "0. 0.7777777777777778\n",
      "b'Success'\n",
      "1. 0.6666666666666666\n",
      "b'Success'\n",
      "2. 0.7777777777777778\n",
      "b'Success'\n",
      "3. 0.7777777777777778\n",
      "b'Success'\n",
      "4. 0.7777777777777778\n",
      "b'Success'\n",
      "5. 0.5555555555555556\n",
      "b'Success'\n",
      "6. 0.8888888888888888\n",
      "b'Success'\n",
      "7. 0.5555555555555556\n",
      "b'Success'\n",
      "8. 0.6666666666666666\n",
      "b'Success'\n",
      "9. 0.8888888888888888\n",
      "b'Success'\n",
      "10. 0.4444444444444444\n",
      "b'Success'\n",
      "11. 0.6666666666666666\n",
      "b'Success'\n",
      "12. 0.5555555555555556\n",
      "b'Success'\n",
      "13. 0.6666666666666666\n",
      "b'Success'\n",
      "14. 0.4444444444444444\n",
      "b'Success'\n",
      "15. 0.6666666666666666\n",
      "b'Success'\n",
      "16. 0.7777777777777778\n",
      "b'Success'\n",
      "17. 0.5555555555555556\n",
      "b'Success'\n",
      "18. 0.7777777777777778\n",
      "b'Success'\n",
      "19. 0.5555555555555556\n",
      "b'Success'\n",
      "20. 0.5555555555555556\n",
      "b'Success'\n",
      "21. 0.6666666666666666\n",
      "b'Success'\n",
      "22. 0.6666666666666666\n",
      "b'Success'\n",
      "23. 0.4444444444444444\n",
      "b'Success'\n",
      "24. 0.6666666666666666\n",
      "b'Success'\n",
      "25. 0.3333333333333333\n",
      "b'Success'\n",
      "26. 0.6666666666666666\n",
      "b'Success'\n",
      "27. 0.7777777777777778\n",
      "b'Success'\n",
      "28. 0.5555555555555556\n",
      "b'Success'\n",
      "29. 0.4444444444444444\n",
      "b'Success'\n",
      "30. 0.7777777777777778\n",
      "b'Success'\n",
      "31. 0.6666666666666666\n",
      "b'Success'\n",
      "32. 0.6666666666666666\n",
      "b'Success'\n",
      "33. 0.6666666666666666\n",
      "b'Success'\n",
      "34. 0.7777777777777778\n",
      "b'Success'\n",
      "35. 0.5555555555555556\n",
      "b'Success'\n",
      "36. 0.4444444444444444\n",
      "b'Success'\n",
      "37. 0.6666666666666666\n",
      "b'Success'\n",
      "38. 0.4444444444444444\n",
      "b'Success'\n",
      "39. 0.6666666666666666\n",
      "b'Success'\n",
      "0.6388888888888888\n",
      "0.1308802109932194\n"
     ]
    }
   ],
   "source": [
    "nRuns = 40\n",
    "C = 0.001\n",
    "timep = 'post'\n",
    "model = f'Logistic Regression L2 C={C}'\n",
    "desc = f'T2D({timep}) vs NGT({timep}) exercise muscle biopsy genecounts W*Count'\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def getSamples(dataMap, timep):\n",
    "    ngt = []\n",
    "    t2d = []\n",
    "    for sid in dataMap['NGT']:\n",
    "        if timep in dataMap[sid]:\n",
    "            ngt.append(dataMap[sid][timep])\n",
    "    for sid in dataMap['T2D']:\n",
    "        if timep in dataMap[sid]:\n",
    "            t2d.append(dataMap[sid][timep])\n",
    "    return np.stack(ngt), np.stack(t2d)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from imagenomer import Analysis, JsonData, JsonSubjects\n",
    "\n",
    "analysis = Analysis(f'{desc}: {model}', 'localhost', 8000)\n",
    "\n",
    "a,b = np.triu_indices(264,1)\n",
    "idcs = np.arange(34716)\n",
    "\n",
    "labels = [f'{a[i]}-{b[i]}' for i in idcs]\n",
    "\n",
    "print(labels[0:10])\n",
    "print(labels[-10:])\n",
    "\n",
    "tot = []\n",
    "\n",
    "for run in range(nRuns):\n",
    "    ngt, t2d = getSamples(dataMap, timep)\n",
    "    np.random.shuffle(ngt)\n",
    "    np.random.shuffle(t2d)\n",
    "    a = int(3*ngt.shape[0]/4)\n",
    "    b = int(3*t2d.shape[0]/4)\n",
    "    c = ngt.shape[0]-a\n",
    "    d = t2d.shape[0]-b\n",
    "    Xtrain = np.concatenate([ngt[:a], t2d[:b]])\n",
    "    Xtest = np.concatenate([ngt[a:], t2d[b:]])\n",
    "    ytrain = np.concatenate([np.zeros(a), np.ones(b)])\n",
    "    ytest = np.concatenate([np.zeros(c), np.ones(d)])\n",
    "    \n",
    "#     mu_Xtrain = np.mean(Xtrain, axis=0, keepdims=True)\n",
    "#     sd_Xtrain = np.std(Xtrain, axis=0, keepdims=True)\n",
    "    \n",
    "#     sd_Xtrain[sd_Xtrain == 0] = 1\n",
    "    \n",
    "#     Xtrain = (Xtrain-mu_Xtrain)/sd_Xtrain\n",
    "#     Xtest = (Xtest-mu_Xtrain)/sd_Xtrain\n",
    "    \n",
    "#     print(Xtrain.shape)\n",
    "#     print(Xtest.shape)\n",
    "#     print(ytrain.shape)\n",
    "#     print(ytest.shape)\n",
    "\n",
    "#     Xtrain = Xtrain[:,imp]\n",
    "#     Xtest = Xtest[:,imp]\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=5000, C=C).fit(Xtrain, ytrain)\n",
    "    yhat = clf.predict(Xtest)\n",
    "    acc = sum(yhat == ytest)/len(ytest)\n",
    "    \n",
    "    print(f'{run}. {acc}')\n",
    "    \n",
    "    tot.append(acc)\n",
    "    \n",
    "#     continue\n",
    "    \n",
    "#     w = clf.coef_.squeeze()\n",
    "#     w = np.mean(np.expand_dims(w,0)*Xtest, axis=0)\n",
    "    \n",
    "    w = clf.coef_.squeeze()\n",
    "#     wNGT = np.mean(np.expand_dims(w,0)*Xtest[:c], axis=0)\n",
    "#     wT2D = np.mean(np.expand_dims(w,0)*Xtest[c:], axis=0)\n",
    "#     w = (wT2D+wNGT)/2\n",
    "    \n",
    "    jsonCompare = desc\n",
    "    jsonAccuracy = acc\n",
    "    jsonTrain = [a,b]\n",
    "    jsonTest = [c,d]\n",
    "    jsonWeights = w\n",
    "    jsonLabels = countNames2 #[int(idx) for idx in list(np.arange(Xtrain.shape[1]))]\n",
    "\n",
    "    jsonObj = {\n",
    "        'Compare': jsonCompare,\n",
    "        'Model': 'Logistic Regression',\n",
    "        'Accuracy': jsonAccuracy,\n",
    "        'Train': jsonTrain,\n",
    "        'Test': jsonTest,\n",
    "        'Weights': list(jsonWeights),\n",
    "        'Labels': jsonLabels\n",
    "    }\n",
    "    \n",
    "    dat = JsonData(analysis)\n",
    "    dat.dict.update(jsonObj)\n",
    "    r = dat.post()\n",
    "    print(r.content)\n",
    "    \n",
    "tot = np.array(tot)\n",
    "print(np.mean(tot))\n",
    "print(np.std(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819fae53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 15, 4, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a33ac551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66023, 36)\n",
      "(66023, 36)\n"
     ]
    }
   ],
   "source": [
    "ngt, t2d = getSamples(dataMap, timep)\n",
    "ngt = np.stack(ngt)\n",
    "t2d = np.stack(t2d)\n",
    "\n",
    "X = np.concatenate([ngt, t2d])\n",
    "X = X.T\n",
    "\n",
    "y = np.concatenate([np.ones((1,len(ngt))), -np.ones((1,len(t2d)))], axis=1)\n",
    "y = np.repeat(y, 66023, axis=0)\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f64c135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66023,)\n",
      "28437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88085/1672266886.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  rho = sxy/np.sqrt(sxx*syy)\n"
     ]
    }
   ],
   "source": [
    "sxy = np.einsum('ab,ab->a',X,y)\n",
    "sxx = np.einsum('ab,ab->a',X,X)\n",
    "syy = np.einsum('ab,ab->a',y,y)\n",
    "\n",
    "rho = sxy/np.sqrt(sxx*syy)\n",
    "\n",
    "print(rho.shape)\n",
    "print(np.sum(np.isnan(rho)))\n",
    "\n",
    "rho[np.isnan(rho)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffafb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
