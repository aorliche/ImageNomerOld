{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e76b7f",
   "metadata": {},
   "source": [
    "# This notebook uses LatSim parameters after hyperparameter tuning\n",
    "\n",
    "Previous notebooks with LatSim do not.\n",
    "This is also a more general version of LatSim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e76f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['FC-slim', 'subjNum2IdxMap', 'subjIdx2NumMap', 'groupsNormalDiagMap'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "fname = '../../data/fmri-FC-slim.pkl'\n",
    "fmriDict = None\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    fmriDict = pickle.load(f)\n",
    "    \n",
    "print(fmriDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5514c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 1, 34716)\n",
      "(66,)\n"
     ]
    }
   ],
   "source": [
    "# Package fMRI data into data matrix and response variables\n",
    "# Important to have a balanced training set\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "keys = list(fmriDict['groupsNormalDiagMap'].keys())\n",
    "y = [fmriDict['groupsNormalDiagMap'][key] for key in keys]\n",
    "y = np.array(y).astype('int')\n",
    "X = [fmriDict['FC-slim'][fmriDict['subjNum2IdxMap'][key]] for key in keys]\n",
    "X = np.stack(X)\n",
    "X = np.expand_dims(X, 1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d3e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../LatentSimilarity')\n",
    "\n",
    "from latsim import LatSim\n",
    "from latsim.util import getAvg, validate, getSparseLoss\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9124f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-1', '0-2', '0-3', '0-4', '0-5', '0-6', '0-7', '0-8', '0-9', '0-10']\n",
      "['259-260', '259-261', '259-262', '259-263', '260-261', '260-262', '260-263', '261-262', '261-263', '262-263']\n",
      "b'Success'\n",
      "0. 0.625\n",
      "0\n",
      "b'Success'\n",
      "b'Success'\n",
      "1. 0.6875\n",
      "1\n",
      "b'Success'\n",
      "b'Success'\n",
      "2. 0.75\n",
      "2\n",
      "b'Success'\n",
      "b'Success'\n",
      "3. 0.75\n",
      "3\n",
      "b'Success'\n",
      "b'Success'\n",
      "4. 0.625\n",
      "4\n",
      "b'Success'\n",
      "b'Success'\n",
      "5. 0.5\n",
      "5\n",
      "b'Success'\n",
      "b'Success'\n",
      "6. 0.6875\n",
      "6\n",
      "b'Success'\n",
      "b'Success'\n",
      "7. 0.75\n",
      "7\n",
      "b'Success'\n",
      "b'Success'\n",
      "8. 0.625\n",
      "8\n",
      "b'Success'\n",
      "b'Success'\n",
      "9. 0.6875\n",
      "9\n",
      "b'Success'\n",
      "b'Success'\n",
      "10. 0.4375\n",
      "10\n",
      "b'Success'\n",
      "b'Success'\n",
      "11. 0.5625\n",
      "11\n",
      "b'Success'\n",
      "b'Success'\n",
      "12. 0.6875\n",
      "12\n",
      "b'Success'\n",
      "b'Success'\n",
      "13. 0.625\n",
      "13\n",
      "b'Success'\n",
      "b'Success'\n",
      "14. 0.625\n",
      "14\n",
      "b'Success'\n",
      "b'Success'\n",
      "15. 0.875\n",
      "15\n",
      "b'Success'\n",
      "b'Success'\n",
      "16. 0.6875\n",
      "16\n",
      "b'Success'\n",
      "b'Success'\n",
      "17. 0.75\n",
      "17\n",
      "b'Success'\n",
      "b'Success'\n",
      "18. 0.5\n",
      "18\n",
      "b'Success'\n",
      "b'Success'\n",
      "19. 0.6875\n",
      "19\n",
      "b'Success'\n",
      "b'Success'\n",
      "20. 0.625\n",
      "20\n",
      "b'Success'\n",
      "b'Success'\n",
      "21. 0.5\n",
      "21\n",
      "b'Success'\n",
      "b'Success'\n",
      "22. 0.5625\n",
      "22\n",
      "b'Success'\n",
      "b'Success'\n",
      "23. 0.875\n",
      "23\n",
      "b'Success'\n",
      "b'Success'\n",
      "24. 0.5625\n",
      "24\n",
      "b'Success'\n",
      "b'Success'\n",
      "25. 0.5625\n",
      "25\n",
      "b'Success'\n",
      "b'Success'\n",
      "26. 0.875\n",
      "26\n",
      "b'Success'\n",
      "b'Success'\n",
      "27. 0.625\n",
      "27\n",
      "b'Success'\n",
      "b'Success'\n",
      "28. 0.6875\n",
      "28\n",
      "b'Success'\n",
      "b'Success'\n",
      "29. 0.75\n",
      "29\n",
      "b'Success'\n",
      "b'Success'\n",
      "30. 0.75\n",
      "30\n",
      "b'Success'\n",
      "b'Success'\n",
      "31. 0.625\n",
      "31\n",
      "b'Success'\n",
      "b'Success'\n",
      "32. 0.625\n",
      "32\n",
      "b'Success'\n",
      "b'Success'\n",
      "33. 0.125\n",
      "33\n",
      "b'Success'\n",
      "b'Success'\n",
      "34. 0.5625\n",
      "34\n",
      "b'Success'\n",
      "b'Success'\n",
      "35. 0.625\n",
      "35\n",
      "b'Success'\n",
      "b'Success'\n",
      "36. 0.75\n",
      "36\n",
      "b'Success'\n",
      "b'Success'\n",
      "37. 0.6875\n",
      "37\n",
      "b'Success'\n",
      "b'Success'\n",
      "38. 0.8125\n",
      "38\n",
      "b'Success'\n",
      "b'Success'\n",
      "39. 0.625\n",
      "39\n",
      "b'Success'\n",
      "b'Success'\n",
      "40. 0.75\n",
      "40\n",
      "b'Success'\n",
      "b'Success'\n",
      "41. 0.75\n",
      "41\n",
      "b'Success'\n",
      "b'Success'\n",
      "42. 0.5\n",
      "42\n",
      "b'Success'\n",
      "b'Success'\n",
      "43. 0.625\n",
      "43\n",
      "b'Success'\n",
      "b'Success'\n",
      "44. 0.625\n",
      "44\n",
      "b'Success'\n",
      "b'Success'\n",
      "45. 0.5625\n",
      "45\n",
      "b'Success'\n",
      "b'Success'\n",
      "46. 0.75\n",
      "46\n",
      "b'Success'\n",
      "b'Success'\n",
      "47. 0.6875\n",
      "47\n",
      "b'Success'\n",
      "b'Success'\n",
      "48. 0.625\n",
      "48\n",
      "b'Success'\n",
      "b'Success'\n",
      "49. 0.75\n",
      "49\n",
      "b'Success'\n",
      "b'Success'\n",
      "0.65125\n",
      "0.12380049474860752\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from imagenomer.main import Analysis, JsonData\n",
    "from imagenomer.metadata import get_power_community_metadata\n",
    "from imagenomer.similarity import get_latsim_similarity\n",
    "\n",
    "a,b = np.triu_indices(264,1)\n",
    "idcs = np.arange(34716)\n",
    "\n",
    "labels = [f'{a[i]}-{b[i]}' for i in idcs]\n",
    "\n",
    "print(labels[0:10])\n",
    "print(labels[-10:])\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "ceLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "nRuns = 50\n",
    "\n",
    "tot = []\n",
    "\n",
    "modelName = 'LatentSimilarity'\n",
    "nEpochs = 200\n",
    "pPeriod = 5\n",
    "thresh = 0.01\n",
    "binParam = 0\n",
    "L2 = 0\n",
    "DP = 0.2\n",
    "EDP = 0.2\n",
    "lr = 1e-1\n",
    "\n",
    "# Create analysis\n",
    "model = f'{modelName} EntropyReg={binParam} L2={L2} DP={DP} EDP={EDP} lr={lr}'\n",
    "desc = 'normal(1) vs. fibromyalgia(0) rest fMRI only, model W'\n",
    "analysis = Analysis(desc=f'{desc}: {model}', \n",
    "                    host='localhost', \n",
    "                    port=8000, \n",
    "                    label_names=['Flattened Indices', 'ROIs'],\n",
    "                    labels=[list(range(X.shape[-1])), labels])\n",
    "\n",
    "# Send community metadata\n",
    "meta = get_power_community_metadata(analysis)\n",
    "r = meta.post()\n",
    "print(r.content)\n",
    "\n",
    "for run in range(nRuns):\n",
    "    FCslim = fmriDict['FC-slim']\n",
    "    subjNum2Idx = fmriDict['subjNum2IdxMap']\n",
    "\n",
    "    # Make a random split\n",
    "    idcs = np.arange(66)\n",
    "    np.random.shuffle(idcs)\n",
    "    trainIdcs = idcs[:50]\n",
    "    testIdcs = idcs[50:]\n",
    "    Xtr = X[trainIdcs]\n",
    "    Xt = X[testIdcs]\n",
    "    ytr = y[trainIdcs]\n",
    "    yt = y[testIdcs]\n",
    "    \n",
    "    # Standardize - good for some datasets but not for others\n",
    "    mu = np.mean(Xtr, axis=0, keepdims=True)\n",
    "    sd = np.std(Xtr, axis=0, keepdims=True)\n",
    "    Xtr = (Xtr-mu)/sd\n",
    "    Xt = (Xt-mu)/sd\n",
    "    \n",
    "    Xtrain_t = torch.from_numpy(Xtr).float().cuda()\n",
    "    Xtest_t = torch.from_numpy(Xt).float().cuda()\n",
    "    ytrain_t = [F.one_hot(torch.from_numpy(ytr)).float().cuda()]\n",
    "    ytest_t = [F.one_hot(torch.from_numpy(yt)).float().cuda()]\n",
    "    X_t = torch.cat([Xtrain_t, Xtest_t])\n",
    "    y_t = [torch.cat([ytrain_t[0], ytest_t[0]])]\n",
    "    \n",
    "    # HC and FM subjects\n",
    "    HCtrain = np.where(ytr == 1)[0]\n",
    "    FMtrain = np.where(ytr == 0)[0]\n",
    "    HCtest = Xtr.shape[0] + np.where(yt == 1)[0]\n",
    "    FMtest = Xtr.shape[0] + np.where(yt == 0)[0]\n",
    "    \n",
    "    sim = LatSim(1, Xtrain_t, dp=DP, edp=EDP, wInit=1e-4, dim=1, temp=1)\n",
    "    optim = torch.optim.Adam(sim.parameters(), lr=lr, weight_decay=L2)\n",
    "    \n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        res = sim(Xtrain_t, ytrain_t)\n",
    "        res = getAvg(res)[0]\n",
    "        loss = []\n",
    "        if ytrain_t[0].ndim > 1:\n",
    "            loss.append(ceLoss(res, ytrain_t[0]))\n",
    "        else:\n",
    "            loss.append(mseLoss(res, ytrain_t[0]))\n",
    "        if binParam is not None and binParam != 0:\n",
    "            loss.append(getSparseLoss(sim, binParam))\n",
    "        sum(loss).backward()\n",
    "        optim.step()\n",
    "#         if epoch % pPeriod == 0 or epoch == nEpochs-1 or all([ls < thresh for ls in loss]):\n",
    "#             print(f'epoch {epoch} loss={loss}')\n",
    "            \n",
    "    ntr = ytrain_t[0].shape[0]\n",
    "    ntst = ytest_t[0].shape[0]\n",
    "    acc = validate(sim, X_t, y_t, np.arange(ntr,ntr+ntst))[0]\n",
    "    _, es = sim(X_t, y_t, np.arange(ntr,ntr+ntst), return_es=True)\n",
    "    \n",
    "    print(f'{run}. {acc}')\n",
    "    \n",
    "    tot.append(float(acc))\n",
    "    \n",
    "    # Difference in w*FC between cohorts\n",
    "    w = np.sum(np.abs(sim.w[0,0].detach().cpu().numpy()), axis=1).astype('float64')\n",
    "    wHC = np.mean(np.expand_dims(w,0)*Xtr[HCtrain,0], axis=0)\n",
    "    wFM = np.mean(np.expand_dims(w,0)*Xtr[FMtrain,0], axis=0)\n",
    "    w = wHC-wFM\n",
    "    w = w\n",
    "\n",
    "    # Send Weights\n",
    "    jsonObj = {\n",
    "        'Compare': desc,\n",
    "        'Model': modelName,\n",
    "        'Accuracy': float(acc),\n",
    "        'Train': [HCtrain.shape[0],FMtrain.shape[0]],\n",
    "        'Test': [33-HCtrain.shape[0],33-FMtrain.shape[0]],\n",
    "        'Weights': list(w) #list(connWmultFC.astype('float64')) \n",
    "    }\n",
    "    \n",
    "    dat = JsonData(analysis)\n",
    "    dat.update(jsonObj)\n",
    "    r = dat.post()\n",
    "    print(dat.dict['runid'])\n",
    "    print(r.content)\n",
    "    \n",
    "    # Send Similarity\n",
    "    sim = get_latsim_similarity(analysis, dat, es[0][0].detach().cpu().numpy(),\n",
    "                                from_ids=list(np.array(keys)[idcs]),\n",
    "                                to_ids=list(np.array(keys)[idcs]),\n",
    "                                groups={\n",
    "                                    'HCtrain': list(HCtrain), \n",
    "                                    'FMtrain': list(FMtrain),\n",
    "                                    'HCtest': list(HCtest),\n",
    "                                    'FMtest': list(FMtest)\n",
    "                                })\n",
    "    r = sim.post()\n",
    "    print(r.content)\n",
    "    \n",
    "#     print(r[:ntr])\n",
    "#     print(r[ntr:])\n",
    "    \n",
    "tot = np.array(tot)\n",
    "print(np.mean(tot))\n",
    "print(np.std(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5e0715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][slice(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05685a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55, 40, 59, 25, 17, 60, 43, 49,  6,  9, 24, 51,  7, 29, 21, 63, 44,\n",
       "       50,  8,  4,  1, 46, 65, 19, 54, 31, 32, 15, 33, 11, 53, 13, 14, 47,\n",
       "       36, 48, 20, 64, 35, 10, 58, 23,  5, 34, 61, 22, 16, 45, 52, 39, 26,\n",
       "       56, 12, 62, 27, 28, 42,  0, 30, 57,  3,  2, 41, 18, 38, 37])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d50779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  5,  7,  9, 11, 13, 15, 17, 19, 22, 23, 25, 27, 29, 31, 34,\n",
       "       35, 37, 40, 41, 44, 48, 49])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HCtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17a440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
